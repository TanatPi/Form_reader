{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909e48cd",
   "metadata": {},
   "source": [
    "# PDF reader and embedder via Azure/ Open AI tools for MM-RAG\n",
    "## ðŸ“˜ Tanat Piumsuwan's Customized Version\n",
    "\n",
    "This notebook also contains scripts for reading and extracting content from PDF files.\n",
    "\n",
    "### âœ… Setup Before Running This Notebook:\n",
    "\n",
    "- Ensure the **corresponding PDF file** is in its designated folder \"\\Data\"\n",
    "- Add yourown .env, based on the empty one I provided.\n",
    "\n",
    "## Environment setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2419664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "pdf_dir = os.getcwd()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "document_basename = os.environ.get(\"DATA_NAME\")\n",
    "pdf_dir = os.path.join(os.getcwd(),'Data')\n",
    "document_name = glob(os.path.join(pdf_dir, \"*.PDF\"))[0]\n",
    "pdf_doc = os.path.join(pdf_dir,document_name )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c47b03",
   "metadata": {},
   "source": [
    "### OpenAI Models information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793c5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `<your-endpoint>` and `<your-key>` variables with the values from the Azure portal\n",
    "DI_endpoint = os.environ.get('DI_ENDPOINT')\n",
    "key = os.environ.get(\"DI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675a865",
   "metadata": {},
   "source": [
    "## Azure DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37f3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, DocumentContentFormat\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def get_words(page, line):\n",
    "    result = []\n",
    "    for word in page.words:\n",
    "        if _in_span(word, line.spans):\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _in_span(word, spans):\n",
    "    for span in spans:\n",
    "        if word.span.offset >= span.offset and (\n",
    "            word.span.offset + word.span.length\n",
    "        ) <= (span.offset + span.length):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def analyze_layout(pdf_doc):\n",
    "    # sample document\n",
    "\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=DI_endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "    # Open your local PDF file\n",
    "    with open(pdf_doc, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            model_id=\"prebuilt-layout\",\n",
    "            body=f,         \n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "\n",
    "    print(\"Extracted keys: \",result.keys())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6930a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=DI_endpoint, credential=AzureKeyCredential(key)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b83ef8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted keys:  dict_keys(['apiVersion', 'modelId', 'stringIndexType', 'content', 'pages', 'tables', 'paragraphs', 'styles', 'contentFormat', 'sections'])\n"
     ]
    }
   ],
   "source": [
    "DI_result = analyze_layout(pdf_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369746d0",
   "metadata": {},
   "source": [
    "## Extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f4097c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Analyzing layout from page #1----\n",
      "No selection marks found on page 1, skipping CSV save.\n",
      "----Analyzing layout from page #2----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_2_selection_marks.csv\n",
      "----Analyzing layout from page #3----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_3_selection_marks.csv\n",
      "----Analyzing layout from page #4----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_4_selection_marks.csv\n",
      "----Analyzing layout from page #5----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_5_selection_marks.csv\n",
      "----Analyzing layout from page #6----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_6_selection_marks.csv\n",
      "----Analyzing layout from page #7----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_7_selection_marks.csv\n",
      "----Analyzing layout from page #8----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_8_selection_marks.csv\n",
      "----Analyzing layout from page #9----\n",
      "No selection marks found on page 9, skipping CSV save.\n",
      "----Analyzing layout from page #10----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_10_selection_marks.csv\n",
      "----Analyzing layout from page #11----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_11_selection_marks.csv\n",
      "----Analyzing layout from page #12----\n",
      "ðŸ“ Saved selection mark texts to CSV: e:\\Work\\KAsset\\Form to csv\\selection_mark_text\\page_12_selection_marks.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def polygon_center(polygon):\n",
    "    # polygon is a list of floats: [x1, y1, x2, y2, x3, y3, x4, y4]\n",
    "    xs = polygon[0::2]\n",
    "    ys = polygon[1::2]\n",
    "    return sum(xs) / len(xs), sum(ys) / len(ys)\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2) ** 0.5\n",
    "\n",
    "def is_near(poly1, poly2, threshold=0.5):\n",
    "    # Threshold in same unit as page dimensions (inch, etc.)\n",
    "    c1 = polygon_center(poly1)\n",
    "    c2 = polygon_center(poly2)\n",
    "    return distance(c1, c2) < threshold\n",
    "\n",
    "# Folder to save CSVs\n",
    "csv_dir = os.path.join(os.getcwd(), 'selection_mark_text')\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "for page in DI_result.pages:\n",
    "    print(f\"----Analyzing layout from page #{page.page_number}----\")\n",
    "\n",
    "    if page.selection_marks:\n",
    "        # List of rows for CSV\n",
    "        csv_rows = []\n",
    "\n",
    "        for sel_mark in page.selection_marks:\n",
    "            sel_center = polygon_center(sel_mark.polygon)\n",
    "            sel_state = sel_mark.state\n",
    "            sel_conf = sel_mark.confidence\n",
    "\n",
    "            # Find lines near selection mark\n",
    "            nearby_texts = []\n",
    "            if page.lines:\n",
    "                for line in page.lines:\n",
    "                    # Each line has a polygon attribute for bounding box? If not, approximate by words\n",
    "                    # Let's get bounding polygon of line by min/max of word polygons\n",
    "                    word_polygons = [word.polygon for word in line.words] if hasattr(line, \"words\") else []\n",
    "                    if not word_polygons:\n",
    "                        # fallback: no polygon for line? Skip or just check line center by words content positions if available\n",
    "                        continue\n",
    "                    \n",
    "                    # Compute bounding polygon of line as min/max of all word polygons\n",
    "                    xs = []\n",
    "                    ys = []\n",
    "                    for poly in word_polygons:\n",
    "                        xs.extend(poly[0::2])\n",
    "                        ys.extend(poly[1::2])\n",
    "                    line_bbox = [min(xs), min(ys), max(xs), min(ys), max(xs), max(ys), min(xs), max(ys)]  # rectangle\n",
    "\n",
    "                    # Check if line bbox is near selection mark polygon center (you could refine this)\n",
    "                    if is_near(sel_mark.polygon, line_bbox, threshold=0.75):\n",
    "                        nearby_texts.append(line.content)\n",
    "\n",
    "            # Join all nearby lines into one string\n",
    "            nearby_text = \" \".join(nearby_texts) if nearby_texts else \"(No nearby text found)\"\n",
    "\n",
    "            csv_rows.append({\n",
    "                \"Page Number\": page.page_number,\n",
    "                \"Selection Mark State\": sel_state,\n",
    "                \"Selection Mark Confidence\": sel_conf,\n",
    "                \"Nearby Text\": nearby_text\n",
    "            })\n",
    "\n",
    "        # Save CSV for this page\n",
    "        csv_path = os.path.join(csv_dir, f\"page_{page.page_number}_selection_marks.csv\")\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            fieldnames = [\"Page Number\", \"Selection Mark State\", \"Selection Mark Confidence\", \"Nearby Text\"]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(csv_rows)\n",
    "\n",
    "        print(f\"ðŸ“ Saved selection mark texts to CSV: {csv_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"No selection marks found on page {page.page_number}, skipping CSV save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
